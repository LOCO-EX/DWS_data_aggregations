{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load libraries, data and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import KDTree\n",
    "#for projections\n",
    "from pyproj import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs----------\n",
    "dsto = xr.open_dataset('') # for bathymetry\n",
    "dsb0 = xr.open_dataset('')\n",
    "dst = xr.open_dataset('') # dir with particle tracks (for getting initial positions)\n",
    "\n",
    "#data for rt\n",
    "PATH_DISC = \"\"\n",
    "#save folder\n",
    "PATH_SAVE_DISC = \"\"\n",
    "\n",
    "#to change - adjust - depends on the amount of data which is to process:\n",
    "START_DATE = 0\n",
    "start_date_str = \"\"\n",
    "units = \"\"\n",
    "YEARS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters---\n",
    "#volume_correction=True\n",
    "npa_per_dep=0 #number of particles per deployment\n",
    "m2=int(0) #period in seconds\n",
    "dx=0;dy=0 #particle initial grid resolution in km\n",
    "#nobs=0   #tracks will have maximum Tr of 116M2 ~ 60days (instead of 90 days)\n",
    "per_min=0 #min % per point of release where at least per_min of the particles leave the DWS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################\n",
    "#create regular grid for statistics (RT, ET, ...) (to use contourf)\n",
    "def create_grid(x0,y0):\n",
    "    xmin=x0.min();xmax=x0.max();ymin=y0.min();ymax=y0.max()\n",
    "    xgrid=np.arange(xmin-dx*1e3,xmax+2*dx*1e3,dx*1e3)\n",
    "    ygrid=np.arange(ymin-dy*1e3,ymax+2*dy*1e3,dy*1e3)\n",
    "    xgrid0,ygrid0=np.meshgrid(xgrid,ygrid)\n",
    "    return xgrid0,ygrid0\n",
    "\n",
    "\n",
    "########################################################\n",
    "#gridding data with nearest\n",
    "def gridding_nearest(var,x0,y0,xgrid,ygrid):\n",
    "    vargrid=xgrid.flatten()*np.nan\n",
    "    tree = KDTree(np.c_[xgrid.flatten(),ygrid.flatten()]) #points in the new extended grid\n",
    "    _,ij = tree.query(np.c_[x0,y0],k=1) #get index for every x0,y0 to put values in the new grid\n",
    "    vargrid[ij]=var\n",
    "    vargrid=np.reshape(vargrid,xgrid.shape)\n",
    "    return vargrid\n",
    "\n",
    "\n",
    "########################################################\n",
    "def create_cmap(numcolors=11,colors=['blue','white','red'],name='create_cmap'):\n",
    "    \"\"\"\n",
    "    Create a custom diverging colormap\n",
    "    Default is blue to white to red with 11 colors. Colors can be specified\n",
    "    in any way understandable by matplotlib.colors.ColorConverter.to_rgb()\n",
    "    \"\"\"\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    cmap = LinearSegmentedColormap.from_list(N=numcolors,colors=colors,name=name)\n",
    "    return cmap\n",
    "\n",
    "########################################################\n",
    "def get_index_valid_points_groupby_bins(npa_per_dep,num_deploys,dat,idp_xy,per_min,typee='out'):\n",
    "    #this is indentical to the above rolling mean, when subsampling=window_length\n",
    "    #this only work for gather data using interval (days) and interval_min_dat (days)\n",
    "    #for gatter data in months use resample\n",
    "    #the advantage of this function in contrast to rolling is that it can be used with data that dont have a dt multiple or divisor of m2 \n",
    " \n",
    "\n",
    "    #1)------------------------------------\n",
    "    #total amount of particles---\n",
    "    npa_total=npa_per_dep*num_deploys \n",
    "    #\n",
    "    #particles stuck---\n",
    "    npa_stuck_xy=(idp_xy==0).sum(dim='timedep')\n",
    "    per_stuck_xy=npa_stuck_xy/num_deploys*100\n",
    "    npa_stuck_total=npa_stuck_xy.sum().values\n",
    "    per_stuck_total=np.round(npa_stuck_total/npa_total*100,2)\n",
    "    #\n",
    "    #particles no stuck but always inside the DWS---\n",
    "    #here there are issues with particles deployed in the bank of the mainland\n",
    "    #they are no stuck but remains almost all the time in the same positions\n",
    "    npa_in_xy=(idp_xy==1).sum(dim='timedep')\n",
    "    per_in_xy=npa_in_xy/num_deploys*100\n",
    "    npa_in_total=npa_in_xy.sum().values\n",
    "    per_in_total=np.round(npa_in_total/npa_total*100,2)\n",
    "    #\n",
    "    #particles that leave at least once the DWS---\n",
    "    npa_out_xy=(idp_xy==2).sum(dim='timedep')\n",
    "    #npa_out_xy=(idp_xy!=1).sum(dim='timedep')\n",
    "    per_out_xy=npa_out_xy/num_deploys*100\n",
    "    npa_out_total=npa_out_xy.sum().values\n",
    "    per_out_total=np.round(npa_out_total/npa_total*100,2)\n",
    "\n",
    "    print(\"particles per deployment =\", npa_per_dep)\n",
    "    print(\"num deployments = \",num_deploys)\n",
    "    print(f\"stuck = {npa_stuck_total}({per_stuck_total}%)\")\n",
    "    print(f\"always inside = {npa_in_total}({per_in_total}%)\")\n",
    "    print(f\"out DWS = {npa_out_total}({per_out_total}%)\")\n",
    "    print(f\"total particles = {npa_total}\")\n",
    " \n",
    "    #2)------------------------------------\n",
    "    #recompute always leaving, considering only points where % > per_min---\n",
    "    #so we are:\n",
    "    #- considering particles that leave at lease once the DWS, which are deployed from regions\n",
    "    #  where they represent more than per_min% of the deployments per grid (25290)\n",
    "    #- helping to avoid problematic regions that tend to have stuck and always inside particles\n",
    "    #this part give particle positions mostly outside banks--\n",
    "    idp_out_opt_xy=(per_out_xy>per_min)\n",
    "    npa_out_opt_xy=npa_out_xy.where(idp_out_opt_xy)\n",
    "    per_out_opt_xy=npa_out_opt_xy/num_deploys*100\n",
    "    npa_out_opt_total=npa_out_opt_xy.sum().values\n",
    "    per_out_opt_total=np.round(npa_out_opt_total/npa_total*100,2)\n",
    "    print(f\"out DWS (> {per_min}% per x,y) = {npa_out_opt_total}({per_out_opt_total}%)\")\n",
    "    #\n",
    "    #get a boolean index when: (idp_xy==2) or (idp_xy>0) and (per_out_xy % > per_min). It is similar to idp_xy but only with True and False---\n",
    "    #this part only modifies above computations if we also consider particles \"always inside DWS\"\n",
    "    if typee=='out': ind_out_opt_xy=(idp_xy==2)*idp_out_opt_xy #consider only \"out\" particles for points where % > per_min\n",
    "    if typee=='inout': ind_out_opt_xy=(idp_xy>0)*idp_out_opt_xy #consider \"always in\" and \"out\" particles for points where % > per_min\n",
    "    per_out_opt_total=np.round(ind_out_opt_xy.sum().values/npa_total*100,2) \n",
    "    print(f\"{typee} DWS (> {per_min}% per x,y) = {ind_out_opt_xy.sum().values}({per_out_opt_total}%)\")\n",
    "    print(f\"num points {typee} DWS = \",idp_out_opt_xy.sum().values)\n",
    "        \n",
    "    return ind_out_opt_xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xct0=dsto.xc.min().values/1e3; yct0=dsto.yc.min().values/1e3 #=(0,0)\n",
    "#create mask for islands from topo file\n",
    "mask=dsto.bathymetry.copy(); mask=xr.where(np.isfinite(mask),1,0) #mask ocean=1, land=0\n",
    "\n",
    "\n",
    "#initial particle positions---\n",
    "x0=dst.x.values; y0=dst.y.values\n",
    "#getting particle position in a grid---\n",
    "xgrid,ygrid=create_grid(x0,y0)\n",
    "\n",
    "bdr_dws0=dsb0.bdr_dws.values #points that define DWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize variables\n",
    "start_date = np.datetime64(start_date_str)\n",
    "date = START_DATE\n",
    "rt_xy = None\n",
    "idp_xy = None\n",
    "time = []\n",
    "\n",
    "rt_15mean = None\n",
    "\n",
    "#loops over years and months\n",
    "for i in range(0,YEARS):\n",
    "    date = date + i\n",
    "    for j in ['01','02','03','04','05','06','07','08','09','10','11','12']: #months\n",
    "        file = PATH_DISC + \"\\\\\" + str(date) + \"\\\\\" + str(date) + j + \".nc\"\n",
    "            \n",
    "        print(\"file: \", file)\n",
    "        #read data : time, rt and idp\n",
    "        rt = xr.open_dataset(file)\n",
    "        time.extend(rt.timedep.values.astype('datetime64[ns]'))\n",
    "        if rt_xy is None:\n",
    "            rt_xy = rt.rt\n",
    "            idp_xy = rt.idp\n",
    "        else:\n",
    "            rt_xy = xr.concat([rt_xy, rt.rt], dim='timedep')\n",
    "            idp_xy = xr.concat([idp_xy, rt.idp], dim='timedep')\n",
    "        rt.close()\n",
    "\n",
    "        #for each 15 days interval\n",
    "        while time[-1] >= start_date + np.timedelta64(15, 'D'):\n",
    "\n",
    "            end_date = start_date + np.timedelta64(15, \"D\")\n",
    "            print(\"\\nstart_date: \", start_date)\n",
    "            print(\"end_date: \", end_date)\n",
    "            rt_15 = rt_xy.sel(timedep=slice(start_date, end_date))\n",
    "            idp_15 = idp_xy.sel(timedep=slice(start_date, end_date))\n",
    "\n",
    "            num_deploys=idp_15.shape[0]\n",
    "\n",
    "            #find indexes of \"good\" particles---\n",
    "            ind_out_opt_xy = get_index_valid_points_groupby_bins(npa_per_dep,num_deploys,rt_15,idp_15,per_min,typee='out')\n",
    "            rt_15out=rt_15.where(ind_out_opt_xy)\n",
    "\n",
    "            #convert to numpy array\n",
    "            rt_15out = np.array(rt_15out)\n",
    "            #mask nan values and compute mean\n",
    "            masked_rt = np.ma.masked_array(rt_15out, np.isnan(rt_15out))\n",
    "            rt_15mean_ = np.mean(masked_rt, axis=0).filled(np.nan)\n",
    "\n",
    "            #griding using 400mx400m squares around the center position of the deployment---\n",
    "            #particles were released skiping every one 200mx200m grid cell, so above grid is just for plotting to cover the full domain and avoid empty spaces \n",
    "            rt_15mean_ = gridding_nearest(rt_15mean_, x0, y0, xgrid, ygrid)\n",
    "\n",
    "            rt_15mean_ = rt_15mean_.reshape(1, rt_15mean_.shape[0], rt_15mean_.shape[1])\n",
    "            \n",
    "            #add the data to list\n",
    "            if rt_15mean is None:\n",
    "                rt_15mean = rt_15mean_\n",
    "            else:\n",
    "                rt_15mean = np.concatenate([rt_15mean, rt_15mean_], axis=0)\n",
    "\n",
    "            #remove data which has been used\n",
    "            rt_xy = rt_xy.sel(timedep=slice(end_date, None))\n",
    "            idp_xy = idp_xy.sel(timedep=slice(end_date, None))\n",
    "            time = [t for t in time if t >= end_date]\n",
    "            \n",
    "            #update start_date\n",
    "            start_date = end_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the coordinate transformations----------\n",
    "#1)\n",
    "#from epgs:28992(DWS) to epgs:4326(LatLon with WGS84 datum used by GPS and Google Earth)\n",
    "proj = Transformer.from_crs('epsg:28992','epsg:4326',always_xy=True)\n",
    "#2)\n",
    "#from epgs:4326(LatLon with WGS84) to epgs:28992(DWS) \n",
    "inproj = Transformer.from_crs('epsg:4326','epsg:28992',always_xy=True)\n",
    "#inproj_old=Proj(\"EPSG:28992\") #old method (has errors 10-20m when contrast with the rotated coords)\n",
    "\n",
    "#lon,lat to 28992(DWS)-projection--------------------\n",
    "\n",
    "#bathymetry--------\n",
    "xct=dsto.lonc.values;  yct=dsto.latc.values #lon,lat units\n",
    "xctp,yctp,z = inproj.transform(xct,yct,xct*0.)\n",
    "xctp=(xctp)/1e3; yctp=(yctp)/1e3 \n",
    "#first projected point to correct the coordinates of model local meter units\n",
    "xctp0=xctp[0,0]; yctp0=yctp[0,0]\n",
    "\n",
    "#matrix rotation -17degrees-----\n",
    "ang=-17*np.pi/180\n",
    "angs=np.ones((2,2))\n",
    "angs[0,0]=np.cos(ang); angs[0,1]=np.sin(ang)\n",
    "angs[1,0]=-np.sin(ang); angs[1,1]=np.cos(ang)\n",
    "\n",
    "\n",
    "#local meter model units to 28992(DWS)-projection and lon-lat--------------\n",
    "\n",
    "#bathymetry----\n",
    "#original topo points in meter\n",
    "xct2,yct2=np.meshgrid(dsto.xc.values,dsto.yc.values)\n",
    "xy=np.array([xct2.flatten(),yct2.flatten()]).T\n",
    "#rotate\n",
    "xyp=np.matmul(angs,xy.T).T/1e3\n",
    "xyp0=xyp[0,:] #the first point in the bathy data in local meter units=0,0\n",
    "\n",
    "#contour of DWS------\n",
    "#rotate\n",
    "bdr_dws0p=np.matmul(angs,bdr_dws0.T).T/1e3\n",
    "#correct model units:\n",
    "#1)substact the first model local point of the topo file, but give tha same as xyp0=[0,0]\n",
    "#2)use the first projected point of the case (lon,lat model units to meter)\n",
    "bdr_dws0p=bdr_dws0p-xyp0 \n",
    "bdr_dws0p[:,0]=bdr_dws0p[:,0]+xctp0; bdr_dws0p[:,1]=bdr_dws0p[:,1]+yctp0\n",
    "#get coordinates in lon-lat units (WGS84 ) \n",
    "bdr_dws0_lon, bdr_dws0_lat, z = proj.transform(bdr_dws0p[:,0]*1e3,bdr_dws0p[:,1]*1e3, bdr_dws0p[:,1]*0.)\n",
    "\n",
    "#regular grid of statistics------\n",
    "xy=np.array([xgrid.flatten(),ygrid.flatten()]).T\n",
    "#rotate\n",
    "xyp=np.matmul(angs,xy.T).T/1e3\n",
    "#correct model units:\n",
    "#1)substact the first model local point of the topo file, but give tha same as xyp0=[0,0]\n",
    "#2)use the first projected point of the case (lon,lat model units to meter)\n",
    "xyp=xyp-xyp0 \n",
    "xyp[:,0]=xyp[:,0]+xctp0; xyp[:,1]=xyp[:,1]+yctp0 \n",
    "xyp=np.reshape(xyp,(xgrid.shape[0],xgrid.shape[1],2))\n",
    "xgridp=xyp[...,0]; ygridp=xyp[...,1] #km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tr---\n",
    "fig=plt.figure(figsize=(7.32,1.95),dpi=600) #120\n",
    "gs = fig.add_gridspec(nrows=1, ncols=2, hspace=.2, wspace=.1)                   \n",
    "cmap=create_cmap(numcolors=2,colors=['w','w'])\n",
    "cmap.set_bad(color='wheat') #nan=gray\n",
    "\n",
    "val=rt_15mean[0]; title=\"15day mean rt\"; lab=\"a)\"\n",
    "#\n",
    "#plot mean---\n",
    "gss=gs[0,0]\n",
    "ax = fig.add_subplot(gss)\n",
    "ax.pcolormesh(xctp[:,:-1],yctp[:,:-1],dsto.bathymetry[:,:-1],vmin=-2,vmax=32,cmap=cmap,shading='auto',rasterized=True,zorder=0) #avoid artificial eastern wall \n",
    "cs=ax.contourf(xgridp,ygridp,val,levels=np.arange(0,30.2,.2),cmap=\"jet\",extend='max',zorder=0) #\"Spectral_r\"\n",
    "ax.contour(xctp[:,:-1],yctp[:,:-1],mask[:,:-1],levels=[1],linewidths=.5,colors='k',zorder=1) #avoid artificial eastern wall\n",
    "ax.plot(bdr_dws0p[:,0],bdr_dws0p[:,1],ls='-',color='k',lw=.8,markersize=0,zorder=2)\n",
    "ax.contour(xctp[:,:-1],yctp[:,:-1],dsto.bathymetry[:,:-1],levels=[5],linewidths=.3,colors='dimgrey',zorder=3)\n",
    "#\n",
    "ax.grid(linewidth=0.4,ls=':')\n",
    "yticks=np.arange(540,640,20); ax.set_yticks(yticks);ax.set_yticklabels(yticks-540);\n",
    "xticks=np.arange(100,240,20); ax.set_xticks(xticks);ax.set_xticklabels(xticks-100);\n",
    "ax.axis('equal'); ax.axis([xticks[0],xticks[-1],yticks[0],yticks[-1]]);\n",
    "ax.tick_params(direction=\"in\")\n",
    "ax.set_title(f\"{title}\")\n",
    "ax.text(102,540+84,lab)\n",
    "ax.set_xlabel('Easting (km)')\n",
    "if i==0: ax.set_ylabel('Northing (km)');\n",
    "if i==1: ax.set_yticklabels(\"\")\n",
    "\n",
    "\n",
    "cbar=fig.colorbar(cs,ax=ax,ticks=np.arange(0,40,10),aspect=10,pad=0.03);\n",
    "cbar.set_label(label=\"Residence time (days)\",rotation=90)\n",
    "cbar.ax.tick_params(labelsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from netCDF4 import date2num\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = datetime.strptime(start_date_str+\" 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "interval = timedelta(days=15)\n",
    "n_periods = len(rt_15mean)\n",
    "middle_times = [start_date + interval * i + interval / 2 for i in range(n_periods)]\n",
    "\n",
    "time = np.array(\n",
    "        date2num(\n",
    "            middle_times, units=units, calendar=\"standard\"\n",
    "        ),\n",
    "        dtype=np.float64,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsout = xr.Dataset()\n",
    "dsout[\"Rt_mean\"]=((\"time\",\"yrc\",\"xrc\"),rt_15mean)\n",
    "dsout[\"Rt_mean\"].attrs[\"long_name\"] = \"mean 15-day residence time\"\n",
    "dsout[\"Rt_mean\"].attrs[\"description\"] = \"NaN values are for points outside DWS and the ones removed from the analysis\"\n",
    "dsout[\"Rt_mean\"].attrs['units'] = 'day'\n",
    "\n",
    "dsout.coords[\"xr\"]=((\"yrc\",\"xrc\"),xgridp)\n",
    "dsout.coords[\"xr\"].attrs[\"long_name\"] = \"x-position for the residence times\"\n",
    "dsout.coords[\"xr\"].attrs['units'] = 'km'\n",
    "dsout.coords[\"yr\"]=((\"yrc\",\"xrc\"),ygridp)\n",
    "dsout.coords[\"yr\"].attrs[\"long_name\"] = \"y-position for the residence times\"\n",
    "dsout.coords[\"yr\"].attrs['units'] = 'km'\n",
    "#\n",
    "dsout.coords[\"xh\"]=((\"yc\",\"xc\"),xctp)\n",
    "dsout.coords[\"yh\"]=((\"yc\",\"xc\"),yctp)\n",
    "dsout.coords[\"xh\"].attrs[\"long_name\"] = \"x-position for the bathymetry\"\n",
    "dsout.coords[\"xh\"].attrs['units'] = 'km'\n",
    "dsout.coords[\"yh\"].attrs[\"long_name\"] = \"y-position for the bathymetry\"\n",
    "dsout.coords[\"yh\"].attrs['units'] = 'km'\n",
    "#\n",
    "dsout.coords[\"time\"]=time\n",
    "dsout.coords[\"time\"].attrs[\"long_name\"] = \"time\"\n",
    "dsout.coords[\"time\"].attrs[\"units\"] = units\n",
    "#\n",
    "dsout[\"h\"]=((\"yc\",\"xc\"),dsto.bathymetry.values)\n",
    "dsout[\"h\"].attrs[\"long_name\"] = \"bathymetry\"\n",
    "dsout[\"h\"].attrs['units'] = 'm'\n",
    "#\n",
    "dsout[\"bdr_dws\"]=((\"np_dws\",\"xy_dws\"),bdr_dws0p)\n",
    "dsout[\"bdr_dws\"].attrs[\"long_name\"] = 'xy coordinates of the boundary of the DWS'\n",
    "dsout[\"bdr_dws\"].attrs['units'] = 'km'\n",
    "\n",
    "\n",
    "dsout.to_netcdf(\"rt_and_rotated_coord.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_dws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
